{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f333a0-7450-4136-b8cc-416e07426279",
   "metadata": {
    "id": "f6f333a0-7450-4136-b8cc-416e07426279"
   },
   "source": [
    "# Interroger des documents (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ca9bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f9ca9bf",
    "outputId": "4112b46b-4271-4696-cf31-393e9e7ff8b3"
   },
   "outputs": [],
   "source": [
    "%pip install -qU wget openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadba81-54dd-48ba-b6f0-fc8307e822c3",
   "metadata": {
    "id": "daadba81-54dd-48ba-b6f0-fc8307e822c3"
   },
   "source": [
    "Commencez par télécharger le document qui va vous servir de base de connaissance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80daa99-3416-4b81-a8aa-4fb7427bbe6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "e80daa99-3416-4b81-a8aa-4fb7427bbe6c",
    "outputId": "abf16516-2ef9-40c3-dcad-74b6f9aa42e6"
   },
   "outputs": [],
   "source": [
    "# Download a file\n",
    "import wget\n",
    "import os\n",
    "\n",
    "file_path = \"my_document.pdf\"\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "doc_url = \"https://www.legifrance.gouv.fr/download/file/rxcTl0H4YnnzLkMLiP4x15qORfLSKk_h8QsSb2xnJ8Y=/JOE_TEXTE\"\n",
    "\n",
    "wget.download(doc_url, out=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf5b47-3ae4-4d86-9012-f2f8379d8f0b",
   "metadata": {
    "id": "80cf5b47-3ae4-4d86-9012-f2f8379d8f0b"
   },
   "source": [
    "Puis instancier la connexion à l'API Albert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90166d",
   "metadata": {
    "id": "db90166d"
   },
   "outputs": [],
   "source": [
    "# OpenAI client configuration\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "base_url = \"https://albert.api.etalab.gouv.fr/v1\"\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "\n",
    "session = requests.session()\n",
    "session.headers = {\"Authorization\": f\"Bearer {api_key}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RkAjTc20Agr9",
   "metadata": {
    "id": "RkAjTc20Agr9"
   },
   "source": [
    "Vous aurez besoin pour la suite d'un modèle de langage ainsi qu'un modèle d'embeddings (pour le RAG). Pour cela vous pouvez appelez le endpoint `/v1/models` pour obtenir la liste des modèles. Les modèles de langage ont le type *text-generation* et les modèles d'embeddings le type *text-embeddings-inference*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q_5YNzmR_JcK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_5YNzmR_JcK",
    "outputId": "01554f0f-3d01-4946-993f-56e657904898"
   },
   "outputs": [],
   "source": [
    "language_model, embeddings_model = None, None\n",
    "\n",
    "for model in client.models.list().data:\n",
    "    if model.type == \"text-generation\" and language_model is None:\n",
    "        language_model = model.id\n",
    "    if model.type == \"text-embeddings-inference\" and embeddings_model is None:\n",
    "        embeddings_model = model.id\n",
    "\n",
    "print(f\"language model: {language_model}\\nembeddings model: {embeddings_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9615d41-5ce2-471b-bd6c-90cfb2b78d21",
   "metadata": {
    "id": "a9615d41-5ce2-471b-bd6c-90cfb2b78d21"
   },
   "source": [
    "Enfin pour vous importer le document dans une collection de notre base vectorielle à l'aide du endpoint POST `/v1/files`.\n",
    "\n",
    "Vous devez spécifier le modèle d'embeddings qui sera utilisé pour vectoriser votre document. Vous pouvez trouver la liste des modèles avec le endpoint `/v1/models`. Les modèles d'embeddings sont indiqués avec le type _feature-extraction_.\n",
    "\n",
    "Le endpoint POST `/v1/files` doit retourner un status _success_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac03e4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ac03e4c",
    "outputId": "6e1c29d9-7d36-4e6c-d7d5-a79305d539cf"
   },
   "outputs": [],
   "source": [
    "# Remove previous files\n",
    "collection = \"tutorial\"\n",
    "response = session.delete(f\"{base_url}/files/{collection}\")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6852fc7a-0b09-451b-bbc2-939fa96a4d28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6852fc7a-0b09-451b-bbc2-939fa96a4d28",
    "outputId": "8555033d-d20f-4b0b-8bfa-7fa5c83a299b"
   },
   "outputs": [],
   "source": [
    "# Upload a file\n",
    "params = {\"collection\": collection, \"embeddings_model\": embeddings_model}\n",
    "\n",
    "files = {\"files\": (os.path.basename(file_path), open(file_path, \"rb\"), \"application/pdf\")}\n",
    "response = session.post(f\"{base_url}/files\", params=params, files=files)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ec73c-3e83-4266-a8de-c6a198f317b4",
   "metadata": {
    "id": "f78ec73c-3e83-4266-a8de-c6a198f317b4"
   },
   "source": [
    "Vous pouvez observer les fichiers que vous avez importer dans une collection à l'aide du endpoint GET `/v1/files.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d6140-5c91-4c3e-9350-b6c8550ab145",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd6d6140-5c91-4c3e-9350-b6c8550ab145",
    "outputId": "0ddea4bb-889e-4ebc-a912-7a2e461ea987"
   },
   "outputs": [],
   "source": [
    "# Retrieve the file ID for RAG\n",
    "response = session.get(f\"{base_url}/files/{collection}\")\n",
    "response.json()\n",
    "file_id = response.json()[\"data\"][0][\"id\"]\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Qui est Ulrich Tan ?\"\n",
    "data = {\"collections\": [collection], \"model\": embeddings_model, \"k\": 6, \"prompt\": prompt}\n",
    "response = session.post(url=f\"{base_url}/search\", json=data, headers={\"Authorization\": f\"Bearer {api_key}\"})\n",
    "\n",
    "prompt_template = \"Réponds à la question suivante en te basant sur les documents ci-dessous : {prompt}\\n\\nDocuments :\\n\\n{chunks}\"\n",
    "chunks = \"\\n\\n\\n\".join([result[\"chunk\"][\"content\"] for result in response.json()[\"data\"]])\n",
    "prompt = prompt_template.format(prompt=prompt, chunks=chunks)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    model=language_model,\n",
    "    stream=False,\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "response = response.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a122cb8",
   "metadata": {},
   "source": [
    "Vous pouvez également faire ajouter une recherche sur internet en spécifiant \"internet\" dans la liste des collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374c1ad-b5ec-4870-a11a-953c7d219f94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f374c1ad-b5ec-4870-a11a-953c7d219f94",
    "outputId": "64279978-1ae5-4bac-f028-bb0899d83d22"
   },
   "outputs": [],
   "source": [
    "prompt = \"Qui est Ulrich Tan ?\"\n",
    "collections = [collection, \"internet\"]\n",
    "data = {\"collections\": collections, \"model\": embeddings_model, \"k\": 6, \"prompt\": prompt}\n",
    "response = session.post(url=f\"{base_url}/search\", json=data, headers={\"Authorization\": f\"Bearer {api_key}\"})\n",
    "\n",
    "prompt_template = \"Réponds à la question suivante en te basant sur les documents ci-dessous : {prompt}\\n\\nDocuments :\\n\\n{chunks}\"\n",
    "chunks = \"\\n\\n\\n\".join([result[\"chunk\"][\"content\"] for result in response.json()[\"data\"]])\n",
    "prompt = prompt_template.format(prompt=prompt, chunks=chunks)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    model=language_model,\n",
    "    stream=False,\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "response = response.choices[0].message.content\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

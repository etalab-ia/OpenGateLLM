{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f333a0-7450-4136-b8cc-416e07426279",
   "metadata": {
    "id": "f6f333a0-7450-4136-b8cc-416e07426279"
   },
   "source": [
    "# Request your knowledge data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9ca9bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f9ca9bf",
    "outputId": "4112b46b-4271-4696-cf31-393e9e7ff8b3"
   },
   "outputs": [],
   "source": [
    "! uv pip install -qU wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "665f1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50a7bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://albert.api.etalab.gouv.fr/v1\"\n",
    "api_key = os.getenv(\"ALBERT_API_KEY\")\n",
    "\n",
    "session = requests.session()\n",
    "session.headers = {\"Authorization\": f\"Bearer {api_key}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadba81-54dd-48ba-b6f0-fc8307e822c3",
   "metadata": {
    "id": "daadba81-54dd-48ba-b6f0-fc8307e822c3"
   },
   "source": [
    "Let's begin by downloading document we're going to use as knowledge base. We're going to use a dataset from data.culture.gouv.fr :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "263f3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_url = \"https://data.culture.gouv.fr/api/explore/v2.1/catalog/datasets?limit=10&offset=0&timezone=UTC&include_links=false&include_app_metas=false\"\n",
    "file_path = \"my_database.json\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    wget.download(doc_url, out=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41e1a7",
   "metadata": {},
   "source": [
    "File format must be JSON for our API endpoint, so no file's conversion required here. But we need to change file's structure to match API requirements. Moreover, file size must be under 20MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bd4f7f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content example : {'visibility': 'domain', 'dataset_id': 'base-des-reliures-numerisees-de-la-bibliotheque-nationale-de-france', 'dataset_uid': 'da_6v5zjp', 'has_records': False, 'features': [], 'attachments': [], 'alternative_exports': [], 'data_visible': True, 'fields': [], 'metas': {'default': {'title': 'Base des reliures numérisées de la Bibliothèque nationale de France', 'description': 'La BnF conserve l’une des plus importantes collections de reliures du monde dont il convenait d’améliorer le signalement pour en favoriser l’étude et la connaissance. Le site reliures.bnf.fr met ainsi en valeur des notices descriptives de reliures qui étaient jusqu’alors peu accessibles à un large public. Dans un premier temps, c’est la description des reliures françaises à décor couvrant la période du début du XVIe siècle au début du XIXe siècle qui a été privilégiée. Le site a été réalisé à partir de l’environnement de data.bnf.fr. Il permet d’agréger des données présentes dans le Catalogue général de la BnF, des représentations numérisées des reliures hébergées dans Gallica et en prévision les données du catalogue BnF Archives et Manuscrits. Ces données sont enrichies de descriptions, scientifiques et complètes des reliures ainsi que des données historiques liées (ateliers de reliure et provenances). Les données présentées dans le site s’appuient sur les technologies avancées et les standards internationaux existants – comme le schéma TEI BnF Reliures – ce qui favorise leur interopérabilité. Enfin, le site offre un environnement de recherche adapté.', 'theme': ['Livre & lecture'], 'keyword': ['librairie', 'livre-ancien', 'reliure', 'bibliothèque'], 'license': 'Licence Ouverte (Etalab)', 'license_url': None, 'language': None, 'metadata_languages': None, 'timezone': None, 'modified': '2020-01-16T16:37:19+00:00', 'modified_updates_on_metadata_change': False, 'modified_updates_on_data_change': False, 'data_processed': None, 'metadata_processed': '2025-06-01T22:00:13.524000+00:00', 'geographic_reference': ['world_fr'], 'geographic_reference_auto': True, 'territory': ['France'], 'geometry_types': None, 'bbox': None, 'publisher': 'Bibliothèque nationale de France', 'references': 'https://www.data.gouv.fr/fr/datasets/base-des-reliures-numerisees-de-la-bibliotheque-nationale-de-france-572265/', 'records_count': 0, 'attributions': None, 'source_domain': None, 'source_domain_title': None, 'source_domain_address': None, 'source_dataset': None, 'shared_catalog': None, 'federated': False, 'parent_domain': None, 'update_frequency': None}, 'custom': {'responsable': None}, 'dcat': {'created': None, 'issued': None, 'creator': None, 'contributor': None, 'contact_name': None, 'contact_email': None, 'accrualperiodicity': None, 'spatial': None, 'temporal': None, 'granularity': None, 'dataquality': None, 'publisher_type': None, 'conforms_to': None, 'temporal_coverage_start': None, 'temporal_coverage_end': None, 'accessRights': None, 'relation': None}}}\n",
      "File size : 56 KB\n"
     ]
    }
   ],
   "source": [
    "file = json.load(open(file_path))['results']\n",
    "\n",
    "print(\"File content example :\", file[0])\n",
    "print(\"File size :\", os.path.getsize(file_path) // 1024, \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f320fe62",
   "metadata": {},
   "source": [
    "Let's start by changing file structure. This one must a list of dictionnary with the following keys : 'title', 'text' and optionaly 'metadata'.\n",
    "\n",
    "We're also going to clean text during this step to remove special characters and format it as expected.\n",
    "\n",
    "In this example, we're going to import first 10  documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90c5ec7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content example : {'title': 'Base des reliures numérisées de la Bibliothèque nationale de France', 'text': 'Base des reliures numérisées de la Bibliothèque nationale de France La BnF conserve l’une des plus importantes collections de reliures du monde dont il convenait d’améliorer le signalement pour en favoriser l’étude et la connaissance. Le site reliures. bnf. fr met ainsi en valeur des notices descriptives de reliures qui étaient jusqu’alors peu accessibles à un large public. Dans un premier temps, c’est la description des reliures françaises à décor couvrant la période du début du XVIe siècle au début du XIXe siècle qui a été privilégiée. Le site a été réalisé à partir de l’environnement de data. bnf. fr. Il permet d’agréger des données présentes dans le Catalogue général de la BnF, des représentations numérisées des reliures hébergées dans Gallica et en prévision les données du catalogue BnF Archives et Manuscrits. Ces données sont enrichies de descriptions, scientifiques et complètes des reliures ainsi que des données historiques liées (ateliers de reliure et provenances). Les données présentées dans le site s’appuient sur les technologies avancées et les standards internationaux existants – comme le schéma TEI BnF Reliures – ce qui favorise leur interopérabilité. Enfin, le site offre un environnement de recherche adapté. base-des-reliures-numerisees-de-la-bibliotheque-nationale-de-france', 'metadata': {'text': 'La BnF conserve l’une des plus importantes collections de reliures du monde dont il convenait d’améliorer le signalement pour en favoriser l’étude et la connaissance. Le site reliures. bnf. fr met ainsi en valeur des notices descriptives de reliures qui étaient jusqu’alors peu accessibles à un large public. Dans un premier temps, c’est la description des reliures françaises à décor couvrant la période du début du XVIe siècle au début du XIXe siècle qui a été privilégiée. Le site a été réalisé à partir de l’environnement de data. bnf. fr. Il permet d’agréger des données présentes dans le Catalogue général de la BnF, des représentations numérisées des reliures hébergées dans Gallica et en prévision les données du catalogue BnF Archives et Manuscrits. Ces données sont enrichies de descriptions, scientifiques et complètes des reliures ainsi que des données historiques liées (ateliers de reliure et provenances). Les données présentées dans le site s’appuient sur les technologies avancées et les standards internationaux existants – comme le schéma TEI BnF Reliures – ce qui favorise leur interopérabilité. Enfin, le site offre un environnement de recherche adapté.', 'titre': 'Base des reliures numérisées de la Bibliothèque nationale de France', 'intitule': 'base-des-reliures-numerisees-de-la-bibliotheque-nationale-de-france'}}\n"
     ]
    }
   ],
   "source": [
    "formated_file = list()\n",
    "sample_size = 10\n",
    "for document in file[:sample_size]:\n",
    "    titre = document.get(\"metas\").get(\"default\").get(\"title\", \"\")\n",
    "    description = document.get(\"metas\").get(\"default\").get(\"description\", \"\")\n",
    "    intitule = document.get(\"dataset_id\", \"\")\n",
    "\n",
    "    text = re.sub(r\"([.,;:!?])([^\\s\\d])\", r\"\\1 \\2\", description)  # Add space after punctuation\n",
    "    text = re.sub(r\"[\\xa0\\u00a0\\r]\", \" \", text)  # Remove special characters\n",
    "    text = re.sub(r\"&nbsp;\", \" \", text)\n",
    "    text = re.sub(r\"\\,(?!\\s)\", \". \", text, count=1)  # Add a space after the first \",\" if not already followed by a space.\n",
    "\n",
    "    formated_file.append(\n",
    "        {\n",
    "            \"title\": titre,\n",
    "            \"text\": f\"{titre} {text} {intitule}\",\n",
    "            \"metadata\": {\"text\": text,  \"titre\": titre, \"intitule\": intitule},\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"File content example : {formated_file[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419fc7b3",
   "metadata": {},
   "source": [
    "Now we can upload files in Albert's vector database. \n",
    "\n",
    "First, let's create a collection named \"tutorial\". To do so, we need to find which model to use, so let's start by requesting '/v1/models' endpoint to get list of available models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd69dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings model: embeddings-small\n"
     ]
    }
   ],
   "source": [
    "response = session.get(f\"{base_url}/models\")\n",
    "response = response.json()\n",
    "model = [model for model in response[\"data\"] if model[\"type\"] == \"text-embeddings-inference\"][0][\"id\"]\n",
    "\n",
    "print(f\"Embeddings model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cc15f7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection ID: 813\n"
     ]
    }
   ],
   "source": [
    "collection = \"tutorial\"\n",
    "\n",
    "response = session.post(f\"{base_url}/collections\", json={\"name\": collection, \"model\": model})\n",
    "response = response.json()\n",
    "collection_id = response[\"id\"]\n",
    "print(f\"Collection ID: {collection_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a84d2a",
   "metadata": {},
   "source": [
    "Now we use Albert API to upload files ine vector database :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6c0cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "for i in range(0, len(formated_file), batch):\n",
    "    batch_file = formated_file[i : i + batch]\n",
    "\n",
    "    batch_file_path = f\"tmp_{i}.json\"\n",
    "    json.dump(batch_file, open(batch_file_path, \"w\"))\n",
    "    assert os.path.getsize(batch_file_path) < 20 * 1024 * 1024\n",
    "\n",
    "    files = {\"file\": (os.path.basename(batch_file_path), open(batch_file_path, \"rb\"), \"application/json\")}\n",
    "    data = {\"request\": '{\"collection\": \"%s\"}' % collection_id}\n",
    "    response = session.post(f\"{base_url}/files\", data=data, files=files)\n",
    "    assert response.status_code == 201, \"Erreur lors de l'importation du fichier\"\n",
    "    document_id = response.json()['id']\n",
    "    os.remove(batch_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RkAjTc20Agr9",
   "metadata": {
    "id": "RkAjTc20Agr9"
   },
   "source": [
    "Let's check if uploaded file is available with GET `/v1/documents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e32a9f8d-5358-4c45-b574-e5bf39dff3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'document',\n",
       " 'id': 820297,\n",
       " 'name': 'Données enquête utilisation des archives recherche universitaire.json',\n",
       " 'collection_id': 812,\n",
       " 'created_at': 1748876074,\n",
       " 'chunks': 3}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = session.get(f\"{base_url}/documents/{document_id}\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0e8eaf",
   "metadata": {},
   "source": [
    "OK, now you know how to create a knowledge base with Albert API. Before uploading your own files, let's remove those we uploaded for this tutorial :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ac03e4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ac03e4c",
    "outputId": "6e1c29d9-7d36-4e6c-d7d5-a79305d539cf"
   },
   "outputs": [],
   "source": [
    "response = session.delete(f\"{base_url}/collections/{collection_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b976882-fd3f-4fb5-a7d3-3e6d14229546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [204]>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d8568-d49d-447c-b64e-c0c6b847fbff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
